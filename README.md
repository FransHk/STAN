# STAN （CVPR2023）

[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/revisiting-temporal-modeling-for-clip-based/video-retrieval-on-msr-vtt-1ka)](https://paperswithcode.com/sota/video-retrieval-on-msr-vtt-1ka?p=revisiting-temporal-modeling-for-clip-based)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/revisiting-temporal-modeling-for-clip-based/video-retrieval-on-didemo)](https://paperswithcode.com/sota/video-retrieval-on-didemo?p=revisiting-temporal-modeling-for-clip-based)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/revisiting-temporal-modeling-for-clip-based/video-retrieval-on-lsmdc)](https://paperswithcode.com/sota/video-retrieval-on-lsmdc?p=revisiting-temporal-modeling-for-clip-based)

Official PyTorch implementation of the CVPR2023 paper ["Revisiting Temporal Modeling for CLIP-based Image-to-Video
Knowledge Transferring"](https://arxiv.org/abs/2301.11116)

All our codes are implemented based on MMaction2. We merely present the method module due to the data module is based on private I/O. The training pipeline will come soon.

## Citation
If you find the code useful for your research, please consider citing our paper:
```
@article{liu2023revisiting,
  title={Revisiting Temporal Modeling for CLIP-based Image-to-Video Knowledge Transferring},
  author={Liu, Ruyang and Huang, Jingjia and Li, Ge and Feng, Jiashi and Wu, Xinglong and Li, Thomas H},
  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2023}
}
```
